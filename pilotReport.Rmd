---
title: "COD Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---

#### Article ID: JcuWB
#### Pilot: Michael Henry Tessler
#### Co-pilot: Tom Hardwicke  
#### Start date: 04/17/2017
#### End date: [Insert end date - use US format]   

-------

#### Methods summary: 
The authors are interested in the "endowment effect" in three-to-four-year-olds.
Specifically, they examine the change in subject valuation (herafter, "value change") of two identical objects which differ in their owner (child vs. experimenter).
They predict an interaction of object-owner with a priming manipulation which focuses the child on her/hisself (vs. focusing on others vs. neural control).
When children are given a distractor task (between the two valuations) that makes them focus on themselves (by drawing a picture of themselves), they will display a greater endowement effect.

------

#### Target outcomes: 

Information about the statistical model (Section 2.2.1):

> To examine the effects of priming on value-change for the two identical endowment toys, a mixed ANCOVA was conducted. Toy owner (child or experimenter) was entered as a repeated measures factor and picture type (self-focus, other- focus, neutral-focus) and gender were entered as a between sub- jects factors. Additionally, child age was normalized and entered as a covariate into the model.

Main results (Section 2.3):

> We found a significant interaction between picture construction condition and toy owner (F(2, 53) = 4.83, p = 0.01, View the MathML source). Specifically, following self-focus, children increased the value of their own toy (M = 0.95, 95% CI = [0.38, 1.52]) but not the experimenter’s toy (M = −0.07, 95% CI = [−0.74, 0.59], t(19) = 3.56, p = 0.01, d = 0.81, Bonferroni corrected). The opposite pattern of responses were observed in the other-focus condition, in which children valued the experimenter’s toy higher (M = 0.86, 95% CI = [0.20, 1.51]), but not their own toy (M = 0.17, 95% CI = [−0.39, 0.73]) - although this effect was not statistically significant (t(19) = −1.61, p = 0.36, d = 0.48, Bonferroni corrected). There was no significant effect of toy owner in the neutral-focus condition (Mchild = 0.89, 95% CIchild = [0.31, 1.46], Mexperimenter = 0.71, 95% CIexperimenter = [0.04, 1.38], t(19) = 0.48, p = 0.64, d = 0.13). The mean value change scores for each condition as a function of toy owner are presented in Fig. 2. We found no significant main effects of types of picture type (Mself = 0.44, 95% CIself = [−0.04, 0.91], Mother = 0.51, 95% CIother = [0.04, 0.98], Mneutral = 0.80, 95% CIneutral = [0.32, 1.28], F(2, 53) = 0.61, p = 0.55, View the MathML source) or toy owner (Mchild = 0.67, 95% CIchild = [0.34, 0.99], Mexperimenter = 0.50, 95% CIexperimenter = [0.12, 0.89], F(1, 53) = 0.55, p = 0.46, View the MathML source). A significant effect of age was observed (F(1, 53) = 7.68, p = 0.01, View the MathML source), indicating that older children increased their valuations more than younger children regardless of toy owner or picture condition. No significant effect of gender (F(1, 53) = 0.46, p = 0.50, View the MathML source), and no significant interactions involving gender or age were observed (Fs < 2.69, ps > 0.11, etc.).



------

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

## Step 1: Load packages

```{r}
library(tidyverse) # for data munging
library(knitr) # for kable table formating
#library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(CODreports) # custom report functions
library(ez)

to.n <- function(fctr){
  return(as.numeric(as.character(fctr)))
}
```

## Step 2: Load data

```{r}
df <- read.csv("data/data.csv")
```

This data frame has 18 variables: 
- participant ID, gender, age, experiment #, prime_type (manipulation), 
- baseline scores for the endowment object(s) (reported in text to be the same for the identical objects for all children), neutral objects, 
- post scores for the endowment object given to the child, experimenter, and for the neutral object
- prime_time is the amount of time spent on the priming / distractor task
- pronouns is number of pronouns of either second person (You, for self-priming) and third person (They, for other priming) in their respective conditions
- I'm not sure what "swap" is
- change scores (post - baseline)

## Step 3: Tidy data

```{r}
df.tidy <- df %>% filter(study == 1) %>%
  separate(prime_time, into =c('min', 'sec'), sep = "min") %>%
  select(-unowned_post, -unowned_change) %>% # not used in expt 1
  separate(age, into = c("year", "month"), sep = "y") %>%
  mutate(sec = gsub("sec", "", sec),
         sec = as.numeric(sec),
         min = as.numeric(min),
         month = as.numeric(gsub("m", "", month)),
         year = as.numeric(year),
         age_in_months = year*12 + month,
         prime_time_seconds = min*60 + sec,
         neutral_baseline = to.n(neutral_baseline),
         experimenter_post = to.n(experimenter_post),
         neutral_post = to.n(neutral_post),
         experimenter_change = to.n(experimenter_change),
         neutral_change = to.n(neutral_change),
         child_baseline = endowment_baseline, # since endowment baseline is the same for both what will become the child's and the experimenter's toys, i create new variables representing this
         experimenter_baseline = endowment_baseline) %>%
  select(-endowment_baseline) %>%
  gather(object, response, ends_with("_baseline"), ends_with("_post"), ends_with("_change")) %>%
  separate(object, into = c("object", "scoringPeriod"))
```

Check the "raw" change scores by subtracting baseline from post

```{r}
df.tidy %>%
  spread(scoringPeriod, response) %>%
  mutate(derivedChange = post - baseline,
         diff = change - derivedChange) %>%
  summarize(totalDeviation = sum(diff))
```
The "change" scores reported in the raw data are the same as "post" - "baseline". Good.

## Step 3: Preprocessing

For ANCOVA, age is normalized
```{r}
mean_age = mean(df.tidy$age_in_months)
sd_age = sd(df.tidy$age_in_months)
df.tidy <- df.tidy %>% 
  mutate(age_normalized = (age_in_months - mean_age) / sd_age)
```


## Step 4: Run analysis

### Descriptive statistics


```{r reported_descriptives}
reported_descriptives <- list(
  self_focus = list(
    child_change = 
      list( mean = 0.95, ci_low = 0.38, ci_high = 1.52), 
    experimenter_change =
      list( mean = -0.07, ci_low = -0.74, ci_high = 0.59)
  ),
  other_focus = list(
    child_change = 
      list( mean = 0.17, ci_low = -0.39, ci_high = 0.73), 
    experimenter_change =
      list( mean = 0.86, ci_low = 0.2, ci_high = 1.51)
  ),
  neutral_focus = list(
    child_change = 
      list( mean = 0.89, ci_low = 0.31, ci_high = 1.46), 
    experimenter_change =
      list( mean = 0.71, ci_low = 0.04, ci_high = 1.38)
  ),
  picture_types = list(
    self = 
     list(mean = 0.44, ci_low = -0.04, ci_high = 0.91),
   other = 
     list(mean = 0.51, ci_low = 0.04, ci_high = 0.98),
   neutral = 
     list(mean = 0.80, ci_low = 0.32, ci_high = 1.28)
   ),
  toy_owner = list(
    child = list(mean = 0.67, ci_low = 0.34, ci_high = 0.99),
    experimenter = list(mean = 0.5, ci_low = 0.12, ci_high = 0.89)
  )
)
```



```{r descriptives_prime_typeXobject}
df.object.prime_type.summary <- df.tidy %>%
  spread(scoringPeriod, response) %>%
  group_by(object, prime_type) %>%
  summarize(
    sample_mean = mean(change),
    sample_sd = sd(change),
    sample_n = n()
  ) %>%
  mutate(
    error = qt(0.975, df = sample_n - 1) * sample_sd / sqrt(sample_n),
    ci_low = sample_mean - error,
    ci_high = sample_mean + error
  )

#########################
# Self Focus: Child Object
#########################
reportedValues = reported_descriptives$self_focus$child_change
obtainedValues = filter(df.object.prime_type.summary, object == "child", prime_type == "self")
## Mean
compareValues(
  reportedValues$mean,
  obtainedValues$sample_mean
)

## CIs (Note that these be off if the mean is off)
compareValues(
  reportedValues$ci_low,
  obtainedValues$ci_low
)

compareValues(
  reportedValues$ci_high,
  obtainedValues$ci_high
)

#########################
# Self Focus: Experimenter Object
#########################
reportedValues_self_experimenter = reported_descriptives$self_focus$experimenter_change
obtainedValues_self_experimenter = filter(df.object.prime_type.summary, 
                                          object == "experimenter", prime_type == "self")
## Mean
compareValues(
  reportedValues_self_experimenter$mean,
  obtainedValues_self_experimenter$sample_mean
)

## CIs (Note that these be off if the mean is off)
compareValues(
  reportedValues_self_experimenter$ci_low,
  obtainedValues_self_experimenter$ci_low
)

compareValues(
  reportedValues_self_experimenter$ci_high,
  obtainedValues_self_experimenter$ci_high
)

#########################
# Other Focus: Child Object
#########################
reportedValues_other_child = reported_descriptives$other_focus$child_change
obtainedValues_other_child = filter(df.object.prime_type.summary, 
                                          object == "child", prime_type == "other")
## Mean
compareValues(
  reportedValues_other_child$mean,
  obtainedValues_other_child$sample_mean
)

## CIs (Note that these be off if the mean is off)
compareValues(
  reportedValues_other_child$ci_low,
  obtainedValues_other_child$ci_low
)

compareValues(
  reportedValues_other_child$ci_high,
  obtainedValues_other_child$ci_high
)

#########################
# Other Focus: Experimenter Object
#########################
reportedValues_other_experimenter = reported_descriptives$other_focus$experimenter_change
obtainedValues_other_experimenter = filter(df.object.prime_type.summary, 
                                          object == "experimenter", prime_type == "other")
## Mean
compareValues(
  reportedValues_other_experimenter$mean,
  obtainedValues_other_experimenter$sample_mean
)

## CIs (Note that these be off if the mean is off)
compareValues(
  reportedValues_other_experimenter$ci_low,
  obtainedValues_other_experimenter$ci_low
)

compareValues(
  reportedValues_other_experimenter$ci_high,
  obtainedValues_other_experimenter$ci_high
)

#########################
# Neutral Focus: Child Object
#########################
reportedValues_neutral_child = reported_descriptives$neutral_focus$child_change
obtainedValues_neutral_child = filter(df.object.prime_type.summary, 
                                          object == "child", prime_type == "neutral")
## Mean
compareValues(
  reportedValues_neutral_child$mean,
  obtainedValues_neutral_child$sample_mean
)

## CIs (Note that these be off if the mean is off)
compareValues(
  reportedValues_neutral_child$ci_low,
  obtainedValues_neutral_child$ci_low
)

compareValues(
  reportedValues_neutral_child$ci_high,
  obtainedValues_neutral_child$ci_high
)

#########################
# Neutral Focus: Experimenter Object
#########################
reportedValues_neutral_experimenter = reported_descriptives$neutral_focus$experimenter_change
obtainedValues_neutral_experimenter = filter(df.object.prime_type.summary, 
                                          object == "experimenter", prime_type == "neutral")
## Mean
compareValues(
  reportedValues_neutral_experimenter$mean,
  obtainedValues_neutral_experimenter$sample_mean
)

## CIs (Note that these be off if the mean is off)
compareValues(
  reportedValues_neutral_experimenter$ci_low,
  obtainedValues_neutral_experimenter$ci_low
)

compareValues(
  reportedValues_neutral_experimenter$ci_high,
  obtainedValues_neutral_experimenter$ci_high
)

```

Overall, my calculations seem to just be slightly off of theirs, but consistently off. Perhaps a subject was excluded that I'm not aware of? (I re-read the relevant text a couple of times, so I'm not sure that's the case). 


```{r descriptives_prime_type}
df.prime_type.summary <- df.tidy %>%
  spread(scoringPeriod, response) %>%
  group_by(prime_type) %>%
  summarize(
    sample_mean = mean(change),
    sample_sd = sd(change),
    sample_n = n()
  ) %>%
  mutate(
    error = qt(0.975, df = sample_n - 1) * sample_sd / sqrt(sample_n),
    ci_low = sample_mean - error,
    ci_high = sample_mean + error
  )

#########################
# Self Focus (collapse across objects)
#########################
reportedValues_selfPrime = reported_descriptives$picture_types$self
obtainedValues_selfPrime = filter(df.prime_type.summary, prime_type == "self")
## Mean
compareValues(
  reportedValues_selfPrime$mean,
  obtainedValues_selfPrime$sample_mean
)

## CIs (Note that these be off if the mean is off)
compareValues(
  reportedValues_selfPrime$ci_low,
  obtainedValues_selfPrime$ci_low
)

compareValues(
  reportedValues_selfPrime$ci_high,
  obtainedValues_selfPrime$ci_high
)

#########################
# Other Focus (collapse across objects)
#########################
reportedValues_otherPrime = reported_descriptives$picture_types$other
obtainedValues_otherPrime = filter(df.prime_type.summary, prime_type == "other")
## Mean
compareValues(
  reportedValues_otherPrime$mean,
  obtainedValues_otherPrime$sample_mean
)

## CIs (Note that these be off if the mean is off)
compareValues(
  reportedValues_otherPrime$ci_low,
  obtainedValues_otherPrime$ci_low
)

compareValues(
  reportedValues_otherPrime$ci_high,
  obtainedValues_otherPrime$ci_high
)

#########################
# Neutral Focus (collapse across objects)
#########################
reportedValues_neutralPrime = reported_descriptives$picture_types$neutral
obtainedValues_neutralPrime = filter(df.prime_type.summary, prime_type == "neutral")
## Mean
compareValues(
  reportedValues_neutralPrime$mean,
  obtainedValues_neutralPrime$sample_mean
)

## CIs (Note that these be off if the mean is off)
compareValues(
  reportedValues_neutralPrime$ci_low,
  obtainedValues_neutralPrime$ci_low
)

compareValues(
  reportedValues_neutralPrime$ci_high,
  obtainedValues_neutralPrime$ci_high
)
```


### Figure 2 in paper

Error bars here denote 95% CIs

```{r figure2}
df.object.prime_type.summary %>%
  filter(object != "neutral") %>%
  mutate(prime_type = factor(prime_type, levels = c("self", "other", "neutral"),
                             labels = c("self", "other", "farm"))) %>%
  ggplot(., aes( x = prime_type, fill = object, group = object,
                 y = sample_mean, ymin = ci_low, ymax = ci_high))+
  geom_col(position = position_dodge(0.7), width = 0.7, color = 'black')+
  geom_errorbar(position = position_dodge(0.7), width = 0.5)+
  ylab("Mean Value Change Score")+
  xlab("Picture Focus")
```





### Inferential statistics



Main results (Section 2.3):

> We found a significant interaction between picture construction condition and toy owner (F(2, 53) = 4.83, p = 0.01, View the MathML source).
> We found a significant interaction between picture construction condition and toy owner (F(2, 53) = 4.83, p = 0.01, View the MathML source). Specifically, following self-focus, children increased the value of their own toy (M = 0.95, 95% CI = [0.38, 1.52]) but not the experimenter’s toy (M = −0.07, 95% CI = [−0.74, 0.59], t(19) = 3.56, p = 0.01, d = 0.81, Bonferroni corrected). The opposite pattern of responses were observed in the other-focus condition, in which children valued the experimenter’s toy higher (M = 0.86, 95% CI = [0.20, 1.51]), but not their own toy (M = 0.17, 95% CI = [−0.39, 0.73]) - although this effect was not statistically significant (t(19) = −1.61, p = 0.36, d = 0.48, Bonferroni corrected). There was no significant effect of toy owner in the neutral-focus condition (Mchild = 0.89, 95% CIchild = [0.31, 1.46], Mexperimenter = 0.71, 95% CIexperimenter = [0.04, 1.38], t(19) = 0.48, p = 0.64, d = 0.13). The mean value change scores for each condition as a function of toy owner are presented in Fig. 2. We found no significant main effects of types of picture type (Mself = 0.44, 95% CIself = [−0.04, 0.91], Mother = 0.51, 95% CIother = [0.04, 0.98], Mneutral = 0.80, 95% CIneutral = [0.32, 1.28], F(2, 53) = 0.61, p = 0.55, View the MathML source) or toy owner (Mchild = 0.67, 95% CIchild = [0.34, 0.99], Mexperimenter = 0.50, 95% CIexperimenter = [0.12, 0.89], F(1, 53) = 0.55, p = 0.46, View the MathML source). A significant effect of age was observed (F(1, 53) = 7.68, p = 0.01, View the MathML source), indicating that older children increased their valuations more than younger children regardless of toy owner or picture condition. No significant effect of gender (F(1, 53) = 0.46, p = 0.50, View the MathML source), and no significant interactions involving gender or age were observed (Fs < 2.69, ps > 0.11, etc.).


```{r fstatistics}

reported_inferentials <- list(
  anova = list(
    interaction = list(dfn = 2, dfd = 53, f = 4.83, p = 0.01),
    age = list(dfn = 1, dfd = 53, f = 7.68, p = 0.01),
    gender = list(dfn = 1, dfd = 53, f = 0.46, p = 0.50)
  ),
  ts = list(
    self_focus_child_experimenter = list(df = 19, t = 3.56, p = 0.01),
    other_focus_child_experimenter = list(df = 19, t = -1.61, p = 0.36),
    neutral_focus_child_experimenter = list(df = 19, t = 0.48, p = 0.64)
  )
)


# > To examine the effects of priming on value-change for the two identical endowment toys, a mixed ANCOVA was conducted. Toy owner (child or experimenter) was entered as a repeated measures factor and picture type (self-focus, other- focus, neutral-focus) and gender were entered as a between sub- jects factors. Additionally, child age was normalized and entered as a covariate into the model.

anova.rs <- ezANOVA(
  df.tidy %>%
    filter(scoringPeriod == "change", object != "neutral") %>%
    mutate(gender = factor(gender)),
  dv = response,
  wid = participant_id,
  within = .(object),
  between = .(prime_type, gender),
  between_covariates = age_normalized,
  detailed = T, return_aov = T
)

reportedValues_ownerPrimeInteraction = reported_inferentials$anova$interaction
obtainedValues_neutralPrimeInteraction = filter(anova.rs$ANOVA, Effect == "prime_type:object")

## df numerator
compareValues(
  reportedValues_ownerPrimeInteraction$dfn,
  obtainedValues_neutralPrimeInteraction$DFn
)

## df denominator
compareValues(
  reportedValues_ownerPrimeInteraction$dfd,
  obtainedValues_neutralPrimeInteraction$DFd
)


## F stat
compareValues(
  reportedValues_ownerPrimeInteraction$f,
  obtainedValues_neutralPrimeInteraction$F
)

## p-value
compareValues(
  reportedValues_ownerPrimeInteraction$p,
  obtainedValues_neutralPrimeInteraction$p, 
  isP = T
)
``` 

Main ANOVA results replicate, though numbers are off a bit.


```{r tstatistics}

reportedValues_ts = reported_inferentials$ts

obtainedValues_selfFocus = with(df.tidy %>%
    filter(scoringPeriod == "change", object != "neutral", prime_type == "self") %>% 
      spread(object, response), 
    t.test(child, experimenter, paired = T))

obtainedValues_otherFocus = with(df.tidy %>%
    filter(scoringPeriod == "change", object != "neutral", prime_type == "other") %>% 
      spread(object, response), 
    t.test(child, experimenter, paired = T))

obtainedValues_neutralFocus = with(df.tidy %>%
    filter(scoringPeriod == "change", object != "neutral", prime_type == "neutral") %>% 
      spread(object, response), 
    t.test(child, experimenter, paired = T))


## T-TEST
### self-focus

compareValues(
  reportedValues_ts$self_focus_child_experimenter$df,
  obtainedValues_selfFocus$parameter
)


compareValues(
  reportedValues_ts$self_focus_child_experimenter$t,
  obtainedValues_selfFocus$statistic
)

compareValues(
  reportedValues_ts$self_focus_child_experimenter$p,
  obtainedValues_selfFocus$p.value, isP = T
)

### other-focus

compareValues(
  reportedValues_ts$other_focus_child_experimenter$df,
  obtainedValues_otherFocus$parameter
)


compareValues(
  reportedValues_ts$other_focus_child_experimenter$t,
  obtainedValues_otherFocus$statistic
)

compareValues(
  reportedValues_ts$other_focus_child_experimenter$p,
  obtainedValues_otherFocus$p.value, isP = T
)

### neutral-focus

compareValues(
  reportedValues_ts$neutral_focus_child_experimenter$df,
  obtainedValues_neutralFocus$parameter
)


compareValues(
  reportedValues_ts$neutral_focus_child_experimenter$t,
  obtainedValues_neutralFocus$statistic
)

compareValues(
  reportedValues_ts$neutral_focus_child_experimenter$p,
  obtainedValues_neutralFocus$p.value, isP = T
)

```

No decision errors! It seems like the authors report all their p-values as p = 0.01 (when in fact they are < 0.01)

## Step 5: Conclusion

```{r}
codReport(Report_Type = 'pilot',
          Article_ID = 'JcuWB', 
          Insufficient_Information_Errors = 0,
          Decision_Errors = 0, 
          Major_Numerical_Errors = 23, 
          Minor_Numerical_Errors = 6)
```


Overall, I think this was a successful replication. The data set has informative labels (though not the best structure for re-analysis, e.g., the "endowment_baseline" applies to both the experimenter_object and the child_object -- which is reported in the paper to be the same -- but to analyze the data, you need to duplicate that column). The vast majority of my exact numerical calculations are off from the authors by varying degrees. This may be because there is a subject that should be excluded, or a small error in my pipeline. 

I also am a little unclear on their reporting of their main ANCOVA. From their text, it seems like normalized age is a covariate (not a factor), but then they report an effect of age. I'm not a ANOVA expert, but when I run the `ezAnova` as I think makes sense, there is no estimate for age effect. So I'm not sure if I'm going wrong somewhere with that. 

23 major numerical errors, but somehow, no decision errors.

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
